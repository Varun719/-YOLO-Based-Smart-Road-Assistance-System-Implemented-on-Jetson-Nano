*Updated Code*
import cv2
from ultralytics import YOLO
from gtts import gTTS
import pygame
import time

# Load the YOLOv8 model 
model = YOLO(r"G:\SRAV2\best (1).pt")
pygame.mixer.init()

# Create a speech file for green light
l = "en-GB"
green_light_text = "Green light detected. It is safe to cross the road now."
green_light_speech = gTTS(text=green_light_text, lang=l, slow=False, tld="com.au")
green_light_speech.save(r"C:\Users\snehs\Downloads\green_light.mp3")
pygame.mixer.music.load(r"C:\Users\snehs\Downloads\green_light.mp3")

# Open the video capture object for the webcam
cap = cv2.VideoCapture(0)

# Initialize variables
lastseen_frames = 0
crosswalk_detected = False

# Get the start time
start_time = time.time()
frame_count = 0

# Loop through the video frames
while cap.isOpened():
    # Read a frame from the video
    success, frame = cap.read()

    if success:
        # Run YOLOv8 inference on the frame
        results = model(frame, conf=0.80)

        # Check if crosswalk is detected
        for r in results:
            for c in r.boxes.cls:
                if r.names[int(c)] == "crosswalk":
                    print("Crosswalk Detected")
                    crosswalk_detected = True
                    lastseen_frames = 0
                    break

        # Check if green light is detected within last 120 frames after crosswalk
        if crosswalk_detected and lastseen_frames <= 120:
            green_light_detected = False
            for r in results:
                for c in r.boxes.cls:
                    if r.names[int(c)] == "green":
                        green_light_detected = True
                        print("Green Light Detected")
                        break
            # If both crosswalk and green light detected within timeframe, play sound
            if green_light_detected and not pygame.mixer.music.get_busy():
                pygame.mixer.music.play()

        # Increment frame count
        lastseen_frames += 1

        # Display the annotated frame
        annotated_frame = results[0].plot()
        cv2.imshow("YOLOv5 Inference", annotated_frame)

        # Calculate and print the FPS
        frame_count += 1
        elapsed_time = time.time() - start_time
        fps = frame_count / elapsed_time
        print(f"FPS: {fps:.2f}")

        # Break the loop if 'q' is pressed
        if cv2.waitKey(1) & 0xFF == ord("q"):
            break
    else:
        # Break the loop if the end of the video is reached
        break

# Release the video capture object and close the display window
cap.release()
cv2.destroyAllWindows()